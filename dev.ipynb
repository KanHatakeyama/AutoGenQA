{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリの自動リロード\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.GGUFBot import GGUFBot\n",
    "from src.HFDataset import HFDataset\n",
    "from src.SimpleQuestionGenerator import SimpleQuestionGenerator\n",
    "from src.AnswerGenerator import AnswerGenerator\n",
    "import pandas as pd\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"minnade/chat-daily\",split=\"train\")\n",
    "dataset=dataset.filter(lambda x: x[\"role\"] == \"user\")\n",
    "\n",
    "questions=[]\n",
    "for d in dataset:\n",
    "    questions.append(d[\"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_layers=30\n",
    "max_new_tokens=4000\n",
    "model_path=\"/home/hatakeyama/python/ChatServer/model/Mixtral-8x22B-Instruct-v0.1.Q5_K_M-00001-of-00004.gguf\"\n",
    "bot=GGUFBot(model_path,max_new_tokens=max_new_tokens,n_ctx=max_new_tokens,n_gpu_layers=n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_gen = AnswerGenerator(bot,n_answers=2)\n",
    "out_path=\"data/augmented_q_and_a.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     355.51 ms /  1513 runs   (    0.23 ms per token,  4255.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21797.48 ms /   940 tokens (   23.19 ms per token,    43.12 tokens per second)\n",
      "llama_print_timings:        eval time =  424020.26 ms /  1512 runs   (  280.44 ms per token,     3.57 tokens per second)\n",
      "llama_print_timings:       total time =  454194.88 ms /  2452 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      71.74 ms /   290 runs   (    0.25 ms per token,  4042.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34714.65 ms /  1526 tokens (   22.75 ms per token,    43.96 tokens per second)\n",
      "llama_print_timings:        eval time =   79615.77 ms /   289 runs   (  275.49 ms per token,     3.63 tokens per second)\n",
      "llama_print_timings:       total time =  115129.32 ms /  1815 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     135.84 ms /   572 runs   (    0.24 ms per token,  4210.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   32998.30 ms /  1527 tokens (   21.61 ms per token,    46.28 tokens per second)\n",
      "llama_print_timings:        eval time =  161050.73 ms /   571 runs   (  282.05 ms per token,     3.55 tokens per second)\n",
      "llama_print_timings:       total time =  195688.53 ms /  2098 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    50 runs   (    0.25 ms per token,  4079.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10707.80 ms /   133 tokens (   80.51 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13753.28 ms /    49 runs   (  280.68 ms per token,     3.56 tokens per second)\n",
      "llama_print_timings:       total time =   24594.47 ms /   182 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      80.43 ms /   338 runs   (    0.24 ms per token,  4202.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10072.35 ms /    63 tokens (  159.88 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:        eval time =   90611.05 ms /   337 runs   (  268.88 ms per token,     3.72 tokens per second)\n",
      "llama_print_timings:       total time =  101574.11 ms /   400 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     102.42 ms /   430 runs   (    0.24 ms per token,  4198.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  114791.95 ms /   430 runs   (  266.96 ms per token,     3.75 tokens per second)\n",
      "llama_print_timings:       total time =  115945.39 ms /   431 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      10.17 ms /    47 runs   (    0.22 ms per token,  4621.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9735.41 ms /   133 tokens (   73.20 ms per token,    13.66 tokens per second)\n",
      "llama_print_timings:        eval time =   12461.77 ms /    46 runs   (  270.91 ms per token,     3.69 tokens per second)\n",
      "llama_print_timings:       total time =   22311.28 ms /   179 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      32.22 ms /   140 runs   (    0.23 ms per token,  4345.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9801.34 ms /    67 tokens (  146.29 ms per token,     6.84 tokens per second)\n",
      "llama_print_timings:        eval time =   38058.04 ms /   139 runs   (  273.80 ms per token,     3.65 tokens per second)\n",
      "llama_print_timings:       total time =   48214.07 ms /   206 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      45.44 ms /   201 runs   (    0.23 ms per token,  4423.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10069.26 ms /    60 tokens (  167.82 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:        eval time =   53388.80 ms /   200 runs   (  266.94 ms per token,     3.75 tokens per second)\n",
      "llama_print_timings:       total time =   63978.75 ms /   260 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     149.72 ms /   641 runs   (    0.23 ms per token,  4281.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10509.66 ms /   129 tokens (   81.47 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:        eval time =  178706.39 ms /   640 runs   (  279.23 ms per token,     3.58 tokens per second)\n",
      "llama_print_timings:       total time =  191023.43 ms /   769 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      56.08 ms /   239 runs   (    0.23 ms per token,  4262.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21439.73 ms /   659 tokens (   32.53 ms per token,    30.74 tokens per second)\n",
      "llama_print_timings:        eval time =   63013.80 ms /   238 runs   (  264.76 ms per token,     3.78 tokens per second)\n",
      "llama_print_timings:       total time =   85082.92 ms /   897 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     175.53 ms /   749 runs   (    0.23 ms per token,  4266.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  200952.99 ms /   749 runs   (  268.30 ms per token,     3.73 tokens per second)\n",
      "llama_print_timings:       total time =  203138.70 ms /   750 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      16.27 ms /    68 runs   (    0.24 ms per token,  4180.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21588.36 ms /   741 tokens (   29.13 ms per token,    34.32 tokens per second)\n",
      "llama_print_timings:        eval time =   17758.70 ms /    67 runs   (  265.06 ms per token,     3.77 tokens per second)\n",
      "llama_print_timings:       total time =   39526.28 ms /   808 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      34.66 ms /   143 runs   (    0.24 ms per token,  4125.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9988.39 ms /    88 tokens (  113.50 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:        eval time =   37483.54 ms /   142 runs   (  263.97 ms per token,     3.79 tokens per second)\n",
      "llama_print_timings:       total time =   47847.05 ms /   230 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      22.24 ms /    92 runs   (    0.24 ms per token,  4135.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10118.26 ms /    77 tokens (  131.41 ms per token,     7.61 tokens per second)\n",
      "llama_print_timings:        eval time =   24603.01 ms /    91 runs   (  270.36 ms per token,     3.70 tokens per second)\n",
      "llama_print_timings:       total time =   34957.99 ms /   168 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      26.05 ms /   109 runs   (    0.24 ms per token,  4184.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9711.87 ms /   168 tokens (   57.81 ms per token,    17.30 tokens per second)\n",
      "llama_print_timings:        eval time =   26431.71 ms /   108 runs   (  244.74 ms per token,     4.09 tokens per second)\n",
      "llama_print_timings:       total time =   36417.27 ms /   276 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      46.38 ms /   193 runs   (    0.24 ms per token,  4161.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10045.27 ms /   122 tokens (   82.34 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:        eval time =   52063.28 ms /   192 runs   (  271.16 ms per token,     3.69 tokens per second)\n",
      "llama_print_timings:       total time =   62612.79 ms /   314 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      94.47 ms /   390 runs   (    0.24 ms per token,  4128.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9739.61 ms /   123 tokens (   79.18 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:        eval time =  104504.57 ms /   389 runs   (  268.65 ms per token,     3.72 tokens per second)\n",
      "llama_print_timings:       total time =  115286.47 ms /   512 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      75.32 ms /   330 runs   (    0.23 ms per token,  4381.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9865.48 ms /   147 tokens (   67.11 ms per token,    14.90 tokens per second)\n",
      "llama_print_timings:        eval time =   90393.25 ms /   329 runs   (  274.75 ms per token,     3.64 tokens per second)\n",
      "llama_print_timings:       total time =  101130.34 ms /   476 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     126.89 ms /   575 runs   (    0.22 ms per token,  4531.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10383.15 ms /   347 tokens (   29.92 ms per token,    33.42 tokens per second)\n",
      "llama_print_timings:        eval time =  151265.29 ms /   574 runs   (  263.53 ms per token,     3.79 tokens per second)\n",
      "llama_print_timings:       total time =  163221.21 ms /   921 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      55.56 ms /   235 runs   (    0.24 ms per token,  4229.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11574.58 ms /   346 tokens (   33.45 ms per token,    29.89 tokens per second)\n",
      "llama_print_timings:        eval time =   66335.85 ms /   234 runs   (  283.49 ms per token,     3.53 tokens per second)\n",
      "llama_print_timings:       total time =   78531.56 ms /   580 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      83.02 ms /   364 runs   (    0.23 ms per token,  4384.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11403.79 ms /   430 tokens (   26.52 ms per token,    37.71 tokens per second)\n",
      "llama_print_timings:        eval time =  101145.32 ms /   363 runs   (  278.64 ms per token,     3.59 tokens per second)\n",
      "llama_print_timings:       total time =  113523.46 ms /   793 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     146.47 ms /   649 runs   (    0.23 ms per token,  4430.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10936.23 ms /   384 tokens (   28.48 ms per token,    35.11 tokens per second)\n",
      "llama_print_timings:        eval time =  176431.34 ms /   648 runs   (  272.27 ms per token,     3.67 tokens per second)\n",
      "llama_print_timings:       total time =  189189.39 ms /  1032 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      30.16 ms /   127 runs   (    0.24 ms per token,  4210.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10525.29 ms /   382 tokens (   27.55 ms per token,    36.29 tokens per second)\n",
      "llama_print_timings:        eval time =   33614.69 ms /   126 runs   (  266.78 ms per token,     3.75 tokens per second)\n",
      "llama_print_timings:       total time =   44458.81 ms /   508 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     111.35 ms /   477 runs   (    0.23 ms per token,  4283.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10530.24 ms /   380 tokens (   27.71 ms per token,    36.09 tokens per second)\n",
      "llama_print_timings:        eval time =  128088.29 ms /   476 runs   (  269.09 ms per token,     3.72 tokens per second)\n",
      "llama_print_timings:       total time =  139922.82 ms /   856 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     119.78 ms /   510 runs   (    0.23 ms per token,  4257.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11171.56 ms /   499 tokens (   22.39 ms per token,    44.67 tokens per second)\n",
      "llama_print_timings:        eval time =  136717.94 ms /   509 runs   (  268.60 ms per token,     3.72 tokens per second)\n",
      "llama_print_timings:       total time =  149295.51 ms /  1008 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      91.52 ms /   392 runs   (    0.23 ms per token,  4283.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10599.34 ms /   490 tokens (   21.63 ms per token,    46.23 tokens per second)\n",
      "llama_print_timings:        eval time =  105491.65 ms /   391 runs   (  269.80 ms per token,     3.71 tokens per second)\n",
      "llama_print_timings:       total time =  117143.57 ms /   881 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     115.22 ms /   487 runs   (    0.24 ms per token,  4226.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20534.59 ms /   581 tokens (   35.34 ms per token,    28.29 tokens per second)\n",
      "llama_print_timings:        eval time =  129959.88 ms /   486 runs   (  267.41 ms per token,     3.74 tokens per second)\n",
      "llama_print_timings:       total time =  151829.66 ms /  1067 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     129.57 ms /   562 runs   (    0.23 ms per token,  4337.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10927.75 ms /   504 tokens (   21.68 ms per token,    46.12 tokens per second)\n",
      "llama_print_timings:        eval time =  151628.77 ms /   561 runs   (  270.28 ms per token,     3.70 tokens per second)\n",
      "llama_print_timings:       total time =  164107.05 ms /  1065 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     182.07 ms /   771 runs   (    0.24 ms per token,  4234.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  204633.70 ms /   771 runs   (  265.41 ms per token,     3.77 tokens per second)\n",
      "llama_print_timings:       total time =  206853.07 ms /   772 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     119.75 ms /   511 runs   (    0.23 ms per token,  4267.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10576.39 ms /   484 tokens (   21.85 ms per token,    45.76 tokens per second)\n",
      "llama_print_timings:        eval time =  133600.64 ms /   510 runs   (  261.96 ms per token,     3.82 tokens per second)\n",
      "llama_print_timings:       total time =  145597.65 ms /   994 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     155.62 ms /   665 runs   (    0.23 ms per token,  4273.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   50326.19 ms /   528 tokens (   95.31 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:        eval time =  177212.30 ms /   664 runs   (  266.89 ms per token,     3.75 tokens per second)\n",
      "llama_print_timings:       total time =  229438.24 ms /  1192 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     112.61 ms /   494 runs   (    0.23 ms per token,  4386.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   49365.29 ms /   525 tokens (   94.03 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:        eval time =  131703.61 ms /   493 runs   (  267.15 ms per token,     3.74 tokens per second)\n",
      "llama_print_timings:       total time =  182413.35 ms /  1018 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      57.86 ms /   254 runs   (    0.23 ms per token,  4390.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10106.16 ms /   120 tokens (   84.22 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:        eval time =   66667.49 ms /   253 runs   (  263.51 ms per token,     3.79 tokens per second)\n",
      "llama_print_timings:       total time =   77422.41 ms /   373 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      78.64 ms /   328 runs   (    0.24 ms per token,  4171.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10663.47 ms /   272 tokens (   39.20 ms per token,    25.51 tokens per second)\n",
      "llama_print_timings:        eval time =   88604.62 ms /   327 runs   (  270.96 ms per token,     3.69 tokens per second)\n",
      "llama_print_timings:       total time =  100130.43 ms /   599 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      41.96 ms /   170 runs   (    0.25 ms per token,  4051.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10493.89 ms /   267 tokens (   39.30 ms per token,    25.44 tokens per second)\n",
      "llama_print_timings:        eval time =   45016.46 ms /   169 runs   (  266.37 ms per token,     3.75 tokens per second)\n",
      "llama_print_timings:       total time =   55949.47 ms /   436 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =       6.20 ms /    26 runs   (    0.24 ms per token,  4192.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9987.83 ms /   354 tokens (   28.21 ms per token,    35.44 tokens per second)\n",
      "llama_print_timings:        eval time =    5727.11 ms /    25 runs   (  229.08 ms per token,     4.37 tokens per second)\n",
      "llama_print_timings:       total time =   15780.62 ms /   379 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     137.17 ms /   567 runs   (    0.24 ms per token,  4133.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9828.82 ms /    43 tokens (  228.58 ms per token,     4.37 tokens per second)\n",
      "llama_print_timings:        eval time =  154038.61 ms /   566 runs   (  272.15 ms per token,     3.67 tokens per second)\n",
      "llama_print_timings:       total time =  165448.26 ms /   609 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      27.25 ms /   118 runs   (    0.23 ms per token,  4330.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9141.39 ms /    42 tokens (  217.65 ms per token,     4.59 tokens per second)\n",
      "llama_print_timings:        eval time =   30158.05 ms /   117 runs   (  257.76 ms per token,     3.88 tokens per second)\n",
      "llama_print_timings:       total time =   39600.65 ms /   159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      11.92 ms /    52 runs   (    0.23 ms per token,  4362.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9892.65 ms /   126 tokens (   78.51 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:        eval time =   13292.59 ms /    51 runs   (  260.64 ms per token,     3.84 tokens per second)\n",
      "llama_print_timings:       total time =   23313.44 ms /   177 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      83.99 ms /   350 runs   (    0.24 ms per token,  4167.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10264.04 ms /    69 tokens (  148.75 ms per token,     6.72 tokens per second)\n",
      "llama_print_timings:        eval time =   93711.95 ms /   349 runs   (  268.52 ms per token,     3.72 tokens per second)\n",
      "llama_print_timings:       total time =  104908.61 ms /   418 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      88.62 ms /   366 runs   (    0.24 ms per token,  4130.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9304.64 ms /    66 tokens (  140.98 ms per token,     7.09 tokens per second)\n",
      "llama_print_timings:        eval time =   96873.74 ms /   365 runs   (  265.41 ms per token,     3.77 tokens per second)\n",
      "llama_print_timings:       total time =  107143.78 ms /   431 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      16.24 ms /    65 runs   (    0.25 ms per token,  4001.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11240.07 ms /   152 tokens (   73.95 ms per token,    13.52 tokens per second)\n",
      "llama_print_timings:        eval time =   16501.07 ms /    64 runs   (  257.83 ms per token,     3.88 tokens per second)\n",
      "llama_print_timings:       total time =   27907.82 ms /   216 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      71.20 ms /   291 runs   (    0.24 ms per token,  4087.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10373.16 ms /    78 tokens (  132.99 ms per token,     7.52 tokens per second)\n",
      "llama_print_timings:        eval time =   72945.53 ms /   290 runs   (  251.54 ms per token,     3.98 tokens per second)\n",
      "llama_print_timings:       total time =   84076.87 ms /   368 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      96.67 ms /   396 runs   (    0.24 ms per token,  4096.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9925.27 ms /    78 tokens (  127.25 ms per token,     7.86 tokens per second)\n",
      "llama_print_timings:        eval time =  160160.57 ms /   395 runs   (  405.47 ms per token,     2.47 tokens per second)\n",
      "llama_print_timings:       total time =  171181.65 ms /   473 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      14.60 ms /    63 runs   (    0.23 ms per token,  4315.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10540.58 ms /   153 tokens (   68.89 ms per token,    14.52 tokens per second)\n",
      "llama_print_timings:        eval time =   18406.13 ms /    62 runs   (  296.87 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =   29102.92 ms /   215 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     111.29 ms /   459 runs   (    0.24 ms per token,  4124.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10831.23 ms /    80 tokens (  135.39 ms per token,     7.39 tokens per second)\n",
      "llama_print_timings:        eval time =  136916.61 ms /   458 runs   (  298.94 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  149005.03 ms /   538 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     135.15 ms /   558 runs   (    0.24 ms per token,  4128.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  166720.63 ms /   558 runs   (  298.78 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  168278.12 ms /   559 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      21.02 ms /    87 runs   (    0.24 ms per token,  4139.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10365.83 ms /   163 tokens (   63.59 ms per token,    15.72 tokens per second)\n",
      "llama_print_timings:        eval time =   24983.14 ms /    86 runs   (  290.50 ms per token,     3.44 tokens per second)\n",
      "llama_print_timings:       total time =   35566.44 ms /   249 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      61.48 ms /   253 runs   (    0.24 ms per token,  4114.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10551.88 ms /   107 tokens (   98.62 ms per token,    10.14 tokens per second)\n",
      "llama_print_timings:        eval time =   74656.15 ms /   252 runs   (  296.25 ms per token,     3.38 tokens per second)\n",
      "llama_print_timings:       total time =   85862.65 ms /   359 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     160.94 ms /   658 runs   (    0.24 ms per token,  4088.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10218.44 ms /    96 tokens (  106.44 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:        eval time =  201072.45 ms /   657 runs   (  306.05 ms per token,     3.27 tokens per second)\n",
      "llama_print_timings:       total time =  213157.23 ms /   753 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      28.86 ms /   118 runs   (    0.24 ms per token,  4089.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10453.24 ms /   172 tokens (   60.77 ms per token,    16.45 tokens per second)\n",
      "llama_print_timings:        eval time =   35833.01 ms /   117 runs   (  306.27 ms per token,     3.27 tokens per second)\n",
      "llama_print_timings:       total time =   46583.18 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     141.37 ms /   570 runs   (    0.25 ms per token,  4031.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10627.42 ms /   136 tokens (   78.14 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:        eval time =  172456.19 ms /   569 runs   (  303.09 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  184668.78 ms /   705 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      52.37 ms /   212 runs   (    0.25 ms per token,  4047.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10594.88 ms /   127 tokens (   83.42 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =   61947.40 ms /   211 runs   (  293.59 ms per token,     3.41 tokens per second)\n",
      "llama_print_timings:       total time =   73082.70 ms /   338 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      27.21 ms /   111 runs   (    0.25 ms per token,  4078.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10584.34 ms /   218 tokens (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_print_timings:        eval time =   31655.80 ms /   110 runs   (  287.78 ms per token,     3.47 tokens per second)\n",
      "llama_print_timings:       total time =   42517.47 ms /   328 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      78.86 ms /   327 runs   (    0.24 ms per token,  4146.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10312.05 ms /   128 tokens (   80.56 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:        eval time =   98441.98 ms /   326 runs   (  301.97 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  109614.62 ms /   454 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      75.30 ms /   317 runs   (    0.24 ms per token,  4209.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10209.43 ms /   127 tokens (   80.39 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:        eval time =   94787.67 ms /   316 runs   (  299.96 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  105846.31 ms /   443 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      31.38 ms /   125 runs   (    0.25 ms per token,  3984.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10863.89 ms /   211 tokens (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:        eval time =   37971.78 ms /   124 runs   (  306.22 ms per token,     3.27 tokens per second)\n",
      "llama_print_timings:       total time =   49158.71 ms /   335 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     123.54 ms /   501 runs   (    0.25 ms per token,  4055.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10381.58 ms /   143 tokens (   72.60 ms per token,    13.77 tokens per second)\n",
      "llama_print_timings:        eval time =  149718.19 ms /   500 runs   (  299.44 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =  161482.39 ms /   643 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     135.34 ms /   566 runs   (    0.24 ms per token,  4182.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  169260.54 ms /   566 runs   (  299.05 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =  170832.39 ms /   567 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      65.10 ms /   297 runs   (    0.22 ms per token,  4562.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11329.19 ms /   420 tokens (   26.97 ms per token,    37.07 tokens per second)\n",
      "llama_print_timings:        eval time =   87988.02 ms /   296 runs   (  297.26 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =  100094.92 ms /   716 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      55.42 ms /   241 runs   (    0.23 ms per token,  4348.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10947.03 ms /   347 tokens (   31.55 ms per token,    31.70 tokens per second)\n",
      "llama_print_timings:        eval time =   71042.24 ms /   240 runs   (  296.01 ms per token,     3.38 tokens per second)\n",
      "llama_print_timings:       total time =   82618.16 ms /   587 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      62.78 ms /   276 runs   (    0.23 ms per token,  4396.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11244.11 ms /   336 tokens (   33.46 ms per token,    29.88 tokens per second)\n",
      "llama_print_timings:        eval time =   82295.55 ms /   275 runs   (  299.26 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =   94270.25 ms /   611 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     198.91 ms /   816 runs   (    0.24 ms per token,  4102.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11195.89 ms /   372 tokens (   30.10 ms per token,    33.23 tokens per second)\n",
      "llama_print_timings:        eval time =  248121.89 ms /   815 runs   (  304.44 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  261727.34 ms /  1187 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     457.89 ms /  1905 runs   (    0.24 ms per token,  4160.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22396.06 ms /   833 tokens (   26.89 ms per token,    37.19 tokens per second)\n",
      "llama_print_timings:        eval time =  590226.46 ms /  1904 runs   (  309.99 ms per token,     3.23 tokens per second)\n",
      "llama_print_timings:       total time =  619393.77 ms /  2737 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     165.17 ms /   686 runs   (    0.24 ms per token,  4153.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22354.69 ms /   832 tokens (   26.87 ms per token,    37.22 tokens per second)\n",
      "llama_print_timings:        eval time =  215417.30 ms /   685 runs   (  314.48 ms per token,     3.18 tokens per second)\n",
      "llama_print_timings:       total time =  239743.28 ms /  1517 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     160.84 ms /   665 runs   (    0.24 ms per token,  4134.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22855.06 ms /   916 tokens (   24.95 ms per token,    40.08 tokens per second)\n",
      "llama_print_timings:        eval time =  204176.31 ms /   664 runs   (  307.49 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =  228949.60 ms /  1580 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     327.46 ms /  1365 runs   (    0.24 ms per token,  4168.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21678.13 ms /   685 tokens (   31.65 ms per token,    31.60 tokens per second)\n",
      "llama_print_timings:        eval time =  415937.90 ms /  1364 runs   (  304.94 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  442014.22 ms /  2049 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     219.58 ms /   912 runs   (    0.24 ms per token,  4153.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  275356.43 ms /   912 runs   (  301.93 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  278083.93 ms /   913 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     160.95 ms /   653 runs   (    0.25 ms per token,  4057.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23219.81 ms /   765 tokens (   30.35 ms per token,    32.95 tokens per second)\n",
      "llama_print_timings:        eval time =  200716.09 ms /   652 runs   (  307.85 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =  225804.17 ms /  1417 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     202.24 ms /   852 runs   (    0.24 ms per token,  4212.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22060.65 ms /   671 tokens (   32.88 ms per token,    30.42 tokens per second)\n",
      "llama_print_timings:        eval time =  255566.86 ms /   851 runs   (  300.31 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  280154.88 ms /  1522 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     229.50 ms /   973 runs   (    0.24 ms per token,  4239.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21965.69 ms /   665 tokens (   33.03 ms per token,    30.27 tokens per second)\n",
      "llama_print_timings:        eval time =  293822.69 ms /   972 runs   (  302.29 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  318737.79 ms /  1637 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     167.33 ms /   684 runs   (    0.24 ms per token,  4087.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22512.23 ms /   751 tokens (   29.98 ms per token,    33.36 tokens per second)\n",
      "llama_print_timings:        eval time =  205907.74 ms /   683 runs   (  301.48 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  230388.64 ms /  1434 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     168.84 ms /   701 runs   (    0.24 ms per token,  4151.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22296.28 ms /   704 tokens (   31.67 ms per token,    31.57 tokens per second)\n",
      "llama_print_timings:        eval time =  212559.43 ms /   700 runs   (  303.66 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =  236887.55 ms /  1404 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     370.23 ms /  1536 runs   (    0.24 ms per token,  4148.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21837.01 ms /   698 tokens (   31.29 ms per token,    31.96 tokens per second)\n",
      "llama_print_timings:        eval time =  471216.18 ms /  1535 runs   (  306.98 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =  498189.38 ms /  2233 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     165.58 ms /   674 runs   (    0.25 ms per token,  4070.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22571.27 ms /   784 tokens (   28.79 ms per token,    34.73 tokens per second)\n",
      "llama_print_timings:        eval time =  203874.96 ms /   673 runs   (  302.93 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  228382.75 ms /  1457 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     359.98 ms /  1496 runs   (    0.24 ms per token,  4155.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21501.19 ms /   687 tokens (   31.30 ms per token,    31.95 tokens per second)\n",
      "llama_print_timings:        eval time =  458366.56 ms /  1495 runs   (  306.60 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =  484816.47 ms /  2182 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     206.43 ms /   853 runs   (    0.24 ms per token,  4132.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21837.18 ms /   690 tokens (   31.65 ms per token,    31.60 tokens per second)\n",
      "llama_print_timings:        eval time =  262226.39 ms /   852 runs   (  307.78 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =  286613.44 ms /  1542 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     157.21 ms /   645 runs   (    0.24 ms per token,  4102.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21987.10 ms /   774 tokens (   28.41 ms per token,    35.20 tokens per second)\n",
      "llama_print_timings:        eval time =  198034.75 ms /   644 runs   (  307.51 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =  221874.49 ms /  1418 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     202.17 ms /   821 runs   (    0.25 ms per token,  4060.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21433.22 ms /   665 tokens (   32.23 ms per token,    31.03 tokens per second)\n",
      "llama_print_timings:        eval time =  250251.87 ms /   820 runs   (  305.19 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  274117.44 ms /  1485 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     213.78 ms /   872 runs   (    0.25 ms per token,  4079.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23231.90 ms /   658 tokens (   35.31 ms per token,    28.32 tokens per second)\n",
      "llama_print_timings:        eval time =  261157.29 ms /   871 runs   (  299.84 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =  286996.14 ms /  1529 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     168.93 ms /   687 runs   (    0.25 ms per token,  4066.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22271.53 ms /   745 tokens (   29.89 ms per token,    33.45 tokens per second)\n",
      "llama_print_timings:        eval time =  207637.18 ms /   686 runs   (  302.68 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  231894.85 ms /  1431 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     262.52 ms /  1085 runs   (    0.24 ms per token,  4133.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21812.89 ms /   705 tokens (   30.94 ms per token,    32.32 tokens per second)\n",
      "llama_print_timings:        eval time =  329297.26 ms /  1084 runs   (  303.78 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =  354456.16 ms /  1789 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     416.44 ms /  1723 runs   (    0.24 ms per token,  4137.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  532796.82 ms /  1723 runs   (  309.23 ms per token,     3.23 tokens per second)\n",
      "llama_print_timings:       total time =  538700.43 ms /  1724 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     183.83 ms /   780 runs   (    0.24 ms per token,  4243.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11129.47 ms /   440 tokens (   25.29 ms per token,    39.53 tokens per second)\n",
      "llama_print_timings:        eval time =  233974.41 ms /   779 runs   (  300.35 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  247363.70 ms /  1219 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     321.13 ms /  1346 runs   (    0.24 ms per token,  4191.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22529.75 ms /   797 tokens (   28.27 ms per token,    35.38 tokens per second)\n",
      "llama_print_timings:        eval time =  404640.98 ms /  1345 runs   (  300.85 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  431523.61 ms /  2142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      89.19 ms /   369 runs   (    0.24 ms per token,  4137.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22155.86 ms /   795 tokens (   27.87 ms per token,    35.88 tokens per second)\n",
      "llama_print_timings:        eval time =  110279.07 ms /   368 runs   (  299.67 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =  133430.30 ms /  1163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      16.04 ms /    71 runs   (    0.23 ms per token,  4426.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10548.39 ms /   138 tokens (   76.44 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:        eval time =   20889.55 ms /    70 runs   (  298.42 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =   31613.24 ms /   208 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     181.76 ms /   758 runs   (    0.24 ms per token,  4170.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10236.34 ms /    88 tokens (  116.32 ms per token,     8.60 tokens per second)\n",
      "llama_print_timings:        eval time =  227170.25 ms /   757 runs   (  300.09 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  239586.10 ms /   845 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     145.47 ms /   603 runs   (    0.24 ms per token,  4145.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10114.93 ms /    85 tokens (  119.00 ms per token,     8.40 tokens per second)\n",
      "llama_print_timings:        eval time =  181890.49 ms /   602 runs   (  302.14 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  193687.33 ms /   687 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      20.41 ms /    83 runs   (    0.25 ms per token,  4066.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10403.27 ms /   171 tokens (   60.84 ms per token,    16.44 tokens per second)\n",
      "llama_print_timings:        eval time =   24345.55 ms /    82 runs   (  296.90 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =   34956.11 ms /   253 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     129.50 ms /   536 runs   (    0.24 ms per token,  4139.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10072.61 ms /   100 tokens (  100.73 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:        eval time =  160564.41 ms /   535 runs   (  300.12 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  172110.34 ms /   635 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     243.54 ms /  1011 runs   (    0.24 ms per token,  4151.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9919.85 ms /    92 tokens (  107.82 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:        eval time =  307277.76 ms /  1010 runs   (  304.24 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =  320257.26 ms /  1102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      94.87 ms /   387 runs   (    0.25 ms per token,  4079.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10498.98 ms /   183 tokens (   57.37 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =  115073.36 ms /   386 runs   (  298.12 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  126614.90 ms /   569 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     127.95 ms /   525 runs   (    0.24 ms per token,  4103.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11131.46 ms /   400 tokens (   27.83 ms per token,    35.93 tokens per second)\n",
      "llama_print_timings:        eval time =  156752.53 ms /   524 runs   (  299.15 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =  169335.62 ms /   924 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     192.27 ms /   793 runs   (    0.24 ms per token,  4124.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  240622.21 ms /   793 runs   (  303.43 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  242945.59 ms /   794 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      97.98 ms /   399 runs   (    0.25 ms per token,  4072.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11325.62 ms /   487 tokens (   23.26 ms per token,    43.00 tokens per second)\n",
      "llama_print_timings:        eval time =  125334.23 ms /   398 runs   (  314.91 ms per token,     3.18 tokens per second)\n",
      "llama_print_timings:       total time =  137740.68 ms /   885 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     139.80 ms /   577 runs   (    0.24 ms per token,  4127.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11121.93 ms /   417 tokens (   26.67 ms per token,    37.49 tokens per second)\n",
      "llama_print_timings:        eval time =  179243.57 ms /   576 runs   (  311.19 ms per token,     3.21 tokens per second)\n",
      "llama_print_timings:       total time =  191995.87 ms /   993 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      96.39 ms /   396 runs   (    0.24 ms per token,  4108.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  120503.47 ms /   396 runs   (  304.30 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =  121574.97 ms /   397 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      25.30 ms /   104 runs   (    0.24 ms per token,  4111.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10430.88 ms /   153 tokens (   68.18 ms per token,    14.67 tokens per second)\n",
      "llama_print_timings:        eval time =   31230.73 ms /   103 runs   (  303.21 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =   41923.73 ms /   256 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      82.90 ms /   339 runs   (    0.24 ms per token,  4089.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10359.84 ms /   117 tokens (   88.55 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:        eval time =  101561.07 ms /   338 runs   (  300.48 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  112819.68 ms /   455 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      37.87 ms /   155 runs   (    0.24 ms per token,  4092.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10341.00 ms /   120 tokens (   86.17 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:        eval time =   46161.80 ms /   154 runs   (  299.75 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =   56897.80 ms /   274 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     125.33 ms /   536 runs   (    0.23 ms per token,  4276.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10295.77 ms /   117 tokens (   88.00 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:        eval time =  158508.76 ms /   535 runs   (  296.28 ms per token,     3.38 tokens per second)\n",
      "llama_print_timings:       total time =  170276.59 ms /   652 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     160.95 ms /   709 runs   (    0.23 ms per token,  4404.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22329.17 ms /   556 tokens (   40.16 ms per token,    24.90 tokens per second)\n",
      "llama_print_timings:        eval time =  218645.03 ms /   708 runs   (  308.82 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =  243005.01 ms /  1264 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     209.36 ms /   933 runs   (    0.22 ms per token,  4456.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20933.70 ms /   550 tokens (   38.06 ms per token,    26.27 tokens per second)\n",
      "llama_print_timings:        eval time =  284258.99 ms /   932 runs   (  305.00 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  307963.26 ms /  1482 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     102.75 ms /   435 runs   (    0.24 ms per token,  4233.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22628.28 ms /   636 tokens (   35.58 ms per token,    28.11 tokens per second)\n",
      "llama_print_timings:        eval time =  132621.56 ms /   434 runs   (  305.58 ms per token,     3.27 tokens per second)\n",
      "llama_print_timings:       total time =  156440.51 ms /  1070 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     233.57 ms /  1006 runs   (    0.23 ms per token,  4307.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11382.23 ms /   452 tokens (   25.18 ms per token,    39.71 tokens per second)\n",
      "llama_print_timings:        eval time =  303656.79 ms /  1005 runs   (  302.15 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  318084.51 ms /  1457 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      94.56 ms /   405 runs   (    0.23 ms per token,  4283.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11824.25 ms /   451 tokens (   26.22 ms per token,    38.14 tokens per second)\n",
      "llama_print_timings:        eval time =  122342.16 ms /   404 runs   (  302.83 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  135262.34 ms /   855 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      15.68 ms /    68 runs   (    0.23 ms per token,  4335.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10317.05 ms /   146 tokens (   70.66 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =   20657.40 ms /    67 runs   (  308.32 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =   31141.95 ms /   213 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      41.96 ms /   182 runs   (    0.23 ms per token,  4337.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10300.56 ms /    86 tokens (  119.77 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:        eval time =   54487.30 ms /   181 runs   (  301.03 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =   65249.17 ms /   267 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      43.19 ms /   184 runs   (    0.23 ms per token,  4260.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10560.28 ms /    77 tokens (  137.15 ms per token,     7.29 tokens per second)\n",
      "llama_print_timings:        eval time =   55005.99 ms /   183 runs   (  300.58 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =   66034.02 ms /   260 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      23.14 ms /    95 runs   (    0.24 ms per token,  4106.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10510.45 ms /   168 tokens (   62.56 ms per token,    15.98 tokens per second)\n",
      "llama_print_timings:        eval time =   27715.14 ms /    94 runs   (  294.84 ms per token,     3.39 tokens per second)\n",
      "llama_print_timings:       total time =   38463.36 ms /   262 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      94.12 ms /   407 runs   (    0.23 ms per token,  4324.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10291.27 ms /   113 tokens (   91.07 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:        eval time =  122049.81 ms /   406 runs   (  300.62 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  133428.10 ms /   519 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     108.68 ms /   475 runs   (    0.23 ms per token,  4370.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10139.69 ms /   108 tokens (   93.89 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:        eval time =  141423.10 ms /   474 runs   (  298.36 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  152853.47 ms /   582 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      37.93 ms /   154 runs   (    0.25 ms per token,  4060.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10653.89 ms /   195 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   45820.60 ms /   153 runs   (  299.48 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =   56877.85 ms /   348 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     132.27 ms /   562 runs   (    0.24 ms per token,  4248.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10384.09 ms /   167 tokens (   62.18 ms per token,    16.08 tokens per second)\n",
      "llama_print_timings:        eval time =  169368.31 ms /   561 runs   (  301.90 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  181329.97 ms /   728 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      78.45 ms /   334 runs   (    0.23 ms per token,  4257.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   99542.30 ms /   334 runs   (  298.03 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =  100439.34 ms /   335 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      38.80 ms /   158 runs   (    0.25 ms per token,  4071.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10695.63 ms /   227 tokens (   47.12 ms per token,    21.22 tokens per second)\n",
      "llama_print_timings:        eval time =   47374.76 ms /   157 runs   (  301.75 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =   58478.62 ms /   384 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      85.55 ms /   355 runs   (    0.24 ms per token,  4149.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10794.28 ms /   175 tokens (   61.68 ms per token,    16.21 tokens per second)\n",
      "llama_print_timings:        eval time =  106336.32 ms /   354 runs   (  300.39 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  118075.20 ms /   529 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      70.60 ms /   293 runs   (    0.24 ms per token,  4149.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   90784.10 ms /   293 runs   (  309.84 ms per token,     3.23 tokens per second)\n",
      "llama_print_timings:       total time =   91559.88 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      55.08 ms /   222 runs   (    0.25 ms per token,  4030.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10783.00 ms /   224 tokens (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_print_timings:        eval time =   66190.97 ms /   221 runs   (  299.51 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =   77556.99 ms /   445 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     155.59 ms /   663 runs   (    0.23 ms per token,  4261.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10606.30 ms /   240 tokens (   44.19 ms per token,    22.63 tokens per second)\n",
      "llama_print_timings:        eval time =  202430.75 ms /   662 runs   (  305.79 ms per token,     3.27 tokens per second)\n",
      "llama_print_timings:       total time =  214936.30 ms /   902 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     178.04 ms /   762 runs   (    0.23 ms per token,  4279.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10339.03 ms /   235 tokens (   44.00 ms per token,    22.73 tokens per second)\n",
      "llama_print_timings:        eval time =  226125.70 ms /   761 runs   (  297.14 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =  238688.98 ms /   996 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      64.65 ms /   267 runs   (    0.24 ms per token,  4130.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10953.54 ms /   322 tokens (   34.02 ms per token,    29.40 tokens per second)\n",
      "llama_print_timings:        eval time =   79034.09 ms /   266 runs   (  297.12 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =   90694.70 ms /   588 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     237.02 ms /   998 runs   (    0.24 ms per token,  4210.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10924.91 ms /   284 tokens (   38.47 ms per token,    26.00 tokens per second)\n",
      "llama_print_timings:        eval time =  300723.47 ms /   997 runs   (  301.63 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  314679.33 ms /  1281 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     218.00 ms /   919 runs   (    0.24 ms per token,  4215.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11141.04 ms /   281 tokens (   39.65 ms per token,    25.22 tokens per second)\n",
      "llama_print_timings:        eval time =  276554.04 ms /   918 runs   (  301.26 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  290460.12 ms /  1199 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      50.83 ms /   210 runs   (    0.24 ms per token,  4131.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11297.21 ms /   308 tokens (   36.68 ms per token,    27.26 tokens per second)\n",
      "llama_print_timings:        eval time =   64053.53 ms /   209 runs   (  306.48 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =   75900.27 ms /   517 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     116.59 ms /   487 runs   (    0.24 ms per token,  4176.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10610.18 ms /   230 tokens (   46.13 ms per token,    21.68 tokens per second)\n",
      "llama_print_timings:        eval time =  152288.38 ms /   486 runs   (  313.35 ms per token,     3.19 tokens per second)\n",
      "llama_print_timings:       total time =  164245.03 ms /   716 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     216.91 ms /   912 runs   (    0.24 ms per token,  4204.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10434.18 ms /   223 tokens (   46.79 ms per token,    21.37 tokens per second)\n",
      "llama_print_timings:        eval time =  286682.87 ms /   911 runs   (  314.69 ms per token,     3.18 tokens per second)\n",
      "llama_print_timings:       total time =  299857.10 ms /  1134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    49 runs   (    0.23 ms per token,  4356.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10177.42 ms /   147 tokens (   69.23 ms per token,    14.44 tokens per second)\n",
      "llama_print_timings:        eval time =   14132.19 ms /    48 runs   (  294.42 ms per token,     3.40 tokens per second)\n",
      "llama_print_timings:       total time =   24432.04 ms /   195 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      57.99 ms /   247 runs   (    0.23 ms per token,  4259.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9969.91 ms /    69 tokens (  144.49 ms per token,     6.92 tokens per second)\n",
      "llama_print_timings:        eval time =   75792.32 ms /   246 runs   (  308.10 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =   86414.38 ms /   315 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      56.85 ms /   252 runs   (    0.23 ms per token,  4432.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10284.63 ms /    58 tokens (  177.32 ms per token,     5.64 tokens per second)\n",
      "llama_print_timings:        eval time =   73579.05 ms /   251 runs   (  293.14 ms per token,     3.41 tokens per second)\n",
      "llama_print_timings:       total time =   84529.31 ms /   309 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      19.26 ms /    80 runs   (    0.24 ms per token,  4154.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10515.74 ms /   149 tokens (   70.58 ms per token,    14.17 tokens per second)\n",
      "llama_print_timings:        eval time =   22488.14 ms /    79 runs   (  284.66 ms per token,     3.51 tokens per second)\n",
      "llama_print_timings:       total time =   33207.62 ms /   228 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     112.31 ms /   494 runs   (    0.23 ms per token,  4398.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10317.32 ms /    98 tokens (  105.28 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:        eval time =  146968.17 ms /   493 runs   (  298.11 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  158656.08 ms /   591 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      97.13 ms /   434 runs   (    0.22 ms per token,  4468.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10137.45 ms /    93 tokens (  109.00 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:        eval time =  127048.98 ms /   433 runs   (  293.42 ms per token,     3.41 tokens per second)\n",
      "llama_print_timings:       total time =  138359.38 ms /   526 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      21.05 ms /    86 runs   (    0.24 ms per token,  4085.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10262.07 ms /   112 tokens (   91.63 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:        eval time =   24928.99 ms /    85 runs   (  293.28 ms per token,     3.41 tokens per second)\n",
      "llama_print_timings:       total time =   35406.86 ms /   197 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      24.47 ms /   101 runs   (    0.24 ms per token,  4127.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10239.59 ms /   106 tokens (   96.60 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:        eval time =   29764.39 ms /   100 runs   (  297.64 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =   40258.32 ms /   206 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     108.71 ms /   445 runs   (    0.24 ms per token,  4093.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10085.60 ms /    95 tokens (  106.16 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:        eval time =  134029.18 ms /   444 runs   (  301.87 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  145333.01 ms /   539 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      52.46 ms /   212 runs   (    0.25 ms per token,  4040.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10375.53 ms /   197 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   62384.83 ms /   211 runs   (  295.66 ms per token,     3.38 tokens per second)\n",
      "llama_print_timings:       total time =   73313.48 ms /   408 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     232.81 ms /   944 runs   (    0.25 ms per token,  4054.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10614.54 ms /   230 tokens (   46.15 ms per token,    21.67 tokens per second)\n",
      "llama_print_timings:        eval time =  283580.93 ms /   943 runs   (  300.72 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  297044.52 ms /  1173 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     173.21 ms /   703 runs   (    0.25 ms per token,  4058.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  209967.14 ms /   703 runs   (  298.67 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  211975.07 ms /   704 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     119.25 ms /   481 runs   (    0.25 ms per token,  4033.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10595.49 ms /   266 tokens (   39.83 ms per token,    25.11 tokens per second)\n",
      "llama_print_timings:        eval time =  144349.61 ms /   480 runs   (  300.73 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  156280.60 ms /   746 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      88.29 ms /   357 runs   (    0.25 ms per token,  4043.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11405.64 ms /   494 tokens (   23.09 ms per token,    43.31 tokens per second)\n",
      "llama_print_timings:        eval time =  109664.38 ms /   356 runs   (  308.05 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =  122031.75 ms /   850 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      69.54 ms /   279 runs   (    0.25 ms per token,  4012.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11435.35 ms /   497 tokens (   23.01 ms per token,    43.46 tokens per second)\n",
      "llama_print_timings:        eval time =   83346.59 ms /   278 runs   (  299.81 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =   95524.78 ms /   775 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      19.79 ms /    81 runs   (    0.24 ms per token,  4093.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10414.66 ms /   179 tokens (   58.18 ms per token,    17.19 tokens per second)\n",
      "llama_print_timings:        eval time =   23998.80 ms /    80 runs   (  299.98 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =   34620.60 ms /   259 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      39.74 ms /   164 runs   (    0.24 ms per token,  4127.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10351.44 ms /   101 tokens (  102.49 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:        eval time =   49031.49 ms /   163 runs   (  300.81 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =   59803.26 ms /   264 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      70.49 ms /   291 runs   (    0.24 ms per token,  4128.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10368.96 ms /    94 tokens (  110.31 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:        eval time =   84001.03 ms /   290 runs   (  289.66 ms per token,     3.45 tokens per second)\n",
      "llama_print_timings:       total time =   95135.75 ms /   384 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      28.96 ms /   116 runs   (    0.25 ms per token,  4005.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10306.12 ms /   181 tokens (   56.94 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   33621.16 ms /   115 runs   (  292.36 ms per token,     3.42 tokens per second)\n",
      "llama_print_timings:       total time =   44221.98 ms /   296 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      93.92 ms /   391 runs   (    0.24 ms per token,  4163.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10088.65 ms /   134 tokens (   75.29 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:        eval time =  118982.18 ms /   390 runs   (  305.08 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  130128.44 ms /   524 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     177.42 ms /   747 runs   (    0.24 ms per token,  4210.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10378.02 ms /   125 tokens (   83.02 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:        eval time =  220157.03 ms /   746 runs   (  295.12 ms per token,     3.39 tokens per second)\n",
      "llama_print_timings:       total time =  232686.59 ms /   871 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    29 runs   (    0.24 ms per token,  4155.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10099.63 ms /   124 tokens (   81.45 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:        eval time =    8950.69 ms /    28 runs   (  319.67 ms per token,     3.13 tokens per second)\n",
      "llama_print_timings:       total time =   19124.47 ms /   152 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    51 runs   (    0.23 ms per token,  4345.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9940.42 ms /    49 tokens (  202.87 ms per token,     4.93 tokens per second)\n",
      "llama_print_timings:        eval time =   14702.47 ms /    50 runs   (  294.05 ms per token,     3.40 tokens per second)\n",
      "llama_print_timings:       total time =   24769.97 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      61.22 ms /   265 runs   (    0.23 ms per token,  4328.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9946.79 ms /    42 tokens (  236.83 ms per token,     4.22 tokens per second)\n",
      "llama_print_timings:        eval time =   79952.72 ms /   264 runs   (  302.85 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =   90594.95 ms /   306 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    36 runs   (    0.24 ms per token,  4190.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10431.83 ms /   129 tokens (   80.87 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:        eval time =    9829.42 ms /    35 runs   (  280.84 ms per token,     3.56 tokens per second)\n",
      "llama_print_timings:       total time =   20349.55 ms /   164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      19.32 ms /    81 runs   (    0.24 ms per token,  4193.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10043.20 ms /    56 tokens (  179.34 ms per token,     5.58 tokens per second)\n",
      "llama_print_timings:        eval time =   25357.82 ms /    80 runs   (  316.97 ms per token,     3.15 tokens per second)\n",
      "llama_print_timings:       total time =   35606.93 ms /   136 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      30.67 ms /   127 runs   (    0.24 ms per token,  4141.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10025.81 ms /    45 tokens (  222.80 ms per token,     4.49 tokens per second)\n",
      "llama_print_timings:        eval time =   37021.02 ms /   126 runs   (  293.82 ms per token,     3.40 tokens per second)\n",
      "llama_print_timings:       total time =   47374.52 ms /   171 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      34.20 ms /   139 runs   (    0.25 ms per token,  4064.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10508.07 ms /   136 tokens (   77.27 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:        eval time =   41737.36 ms /   138 runs   (  302.44 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =   52604.94 ms /   274 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     128.50 ms /   543 runs   (    0.24 ms per token,  4225.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10475.93 ms /   156 tokens (   67.15 ms per token,    14.89 tokens per second)\n",
      "llama_print_timings:        eval time =  163971.38 ms /   542 runs   (  302.53 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  175956.70 ms /   698 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      55.22 ms /   234 runs   (    0.24 ms per token,  4237.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10487.07 ms /   155 tokens (   67.66 ms per token,    14.78 tokens per second)\n",
      "llama_print_timings:        eval time =   71803.47 ms /   233 runs   (  308.17 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =   82899.97 ms /   388 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      44.99 ms /   185 runs   (    0.24 ms per token,  4111.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10586.84 ms /   239 tokens (   44.30 ms per token,    22.58 tokens per second)\n",
      "llama_print_timings:        eval time =   53380.60 ms /   184 runs   (  290.11 ms per token,     3.45 tokens per second)\n",
      "llama_print_timings:       total time =   64440.89 ms /   423 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      49.32 ms /   207 runs   (    0.24 ms per token,  4196.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10510.30 ms /   198 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   62979.99 ms /   206 runs   (  305.73 ms per token,     3.27 tokens per second)\n",
      "llama_print_timings:       total time =   74027.24 ms /   404 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      70.35 ms /   302 runs   (    0.23 ms per token,  4292.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10536.27 ms /   198 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   93775.01 ms /   301 runs   (  311.54 ms per token,     3.21 tokens per second)\n",
      "llama_print_timings:       total time =  105101.29 ms /   499 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      54.09 ms /   227 runs   (    0.24 ms per token,  4196.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10618.41 ms /   285 tokens (   37.26 ms per token,    26.84 tokens per second)\n",
      "llama_print_timings:        eval time =   70308.29 ms /   226 runs   (  311.10 ms per token,     3.21 tokens per second)\n",
      "llama_print_timings:       total time =   81519.52 ms /   511 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    43 runs   (    0.24 ms per token,  4222.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10623.08 ms /   247 tokens (   43.01 ms per token,    23.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12636.87 ms /    42 runs   (  300.88 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =   23368.97 ms /   289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      15.89 ms /    65 runs   (    0.24 ms per token,  4091.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10514.56 ms /   236 tokens (   44.55 ms per token,    22.45 tokens per second)\n",
      "llama_print_timings:        eval time =   18834.62 ms /    64 runs   (  294.29 ms per token,     3.40 tokens per second)\n",
      "llama_print_timings:       total time =   29511.63 ms /   300 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      48.83 ms /   206 runs   (    0.24 ms per token,  4218.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11075.87 ms /   327 tokens (   33.87 ms per token,    29.52 tokens per second)\n",
      "llama_print_timings:        eval time =   62138.29 ms /   205 runs   (  303.11 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =   73748.91 ms /   532 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     144.44 ms /   622 runs   (    0.23 ms per token,  4306.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10526.69 ms /   224 tokens (   46.99 ms per token,    21.28 tokens per second)\n",
      "llama_print_timings:        eval time =  187167.46 ms /   621 runs   (  301.40 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  199452.68 ms /   845 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      93.59 ms /   407 runs   (    0.23 ms per token,  4348.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  122870.76 ms /   407 runs   (  301.89 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  123959.67 ms /   408 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      41.36 ms /   173 runs   (    0.24 ms per token,  4182.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10651.83 ms /   262 tokens (   40.66 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:        eval time =   52515.68 ms /   172 runs   (  305.32 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =   63612.56 ms /   434 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      82.70 ms /   342 runs   (    0.24 ms per token,  4135.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10564.28 ms /   193 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =  101734.05 ms /   341 runs   (  298.34 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  113207.18 ms /   534 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     157.19 ms /   676 runs   (    0.23 ms per token,  4300.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10465.63 ms /   187 tokens (   55.97 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =  202563.42 ms /   675 runs   (  300.09 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  214958.17 ms /   862 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      19.50 ms /    84 runs   (    0.23 ms per token,  4307.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10455.85 ms /   122 tokens (   85.70 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:        eval time =   24712.80 ms /    83 runs   (  297.74 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =   35376.74 ms /   205 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      37.05 ms /   167 runs   (    0.22 ms per token,  4507.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10206.77 ms /   101 tokens (  101.06 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:        eval time =   49004.89 ms /   166 runs   (  295.21 ms per token,     3.39 tokens per second)\n",
      "llama_print_timings:       total time =   59633.46 ms /   267 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      13.06 ms /    57 runs   (    0.23 ms per token,  4363.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10129.67 ms /   100 tokens (  101.30 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:        eval time =   16706.44 ms /    56 runs   (  298.33 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =   26978.50 ms /   156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      17.09 ms /    75 runs   (    0.23 ms per token,  4387.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10248.28 ms /   128 tokens (   80.06 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:        eval time =   22006.78 ms /    74 runs   (  297.39 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =   32441.75 ms /   202 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     159.37 ms /   661 runs   (    0.24 ms per token,  4147.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10082.60 ms /    93 tokens (  108.42 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:        eval time =  208270.39 ms /   660 runs   (  315.56 ms per token,     3.17 tokens per second)\n",
      "llama_print_timings:       total time =  220237.70 ms /   753 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     153.08 ms /   638 runs   (    0.24 ms per token,  4167.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10241.93 ms /    91 tokens (  112.55 ms per token,     8.89 tokens per second)\n",
      "llama_print_timings:        eval time =  200749.87 ms /   637 runs   (  315.15 ms per token,     3.17 tokens per second)\n",
      "llama_print_timings:       total time =  212779.68 ms /   728 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     173.23 ms /   720 runs   (    0.24 ms per token,  4156.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10842.22 ms /   175 tokens (   61.96 ms per token,    16.14 tokens per second)\n",
      "llama_print_timings:        eval time =  218071.85 ms /   719 runs   (  303.30 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  230982.16 ms /   894 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     196.18 ms /   813 runs   (    0.24 ms per token,  4144.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22213.94 ms /   733 tokens (   30.31 ms per token,    33.00 tokens per second)\n",
      "llama_print_timings:        eval time =  248821.20 ms /   812 runs   (  306.43 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =  273433.30 ms /  1545 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     153.27 ms /   633 runs   (    0.24 ms per token,  4129.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22320.78 ms /   733 tokens (   30.45 ms per token,    32.84 tokens per second)\n",
      "llama_print_timings:        eval time =  192346.87 ms /   632 runs   (  304.35 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =  216477.11 ms /  1365 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     146.56 ms /   601 runs   (    0.24 ms per token,  4100.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22491.19 ms /   820 tokens (   27.43 ms per token,    36.46 tokens per second)\n",
      "llama_print_timings:        eval time =  185097.86 ms /   600 runs   (  308.50 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =  209288.48 ms /  1420 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     194.89 ms /   816 runs   (    0.24 ms per token,  4187.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21731.76 ms /   614 tokens (   35.39 ms per token,    28.25 tokens per second)\n",
      "llama_print_timings:        eval time =  251592.87 ms /   815 runs   (  308.70 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =  275702.72 ms /  1429 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     145.84 ms /   600 runs   (    0.24 ms per token,  4114.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21665.07 ms /   614 tokens (   35.29 ms per token,    28.34 tokens per second)\n",
      "llama_print_timings:        eval time =  180509.85 ms /   599 runs   (  301.35 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  203860.23 ms /  1213 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      37.54 ms /   158 runs   (    0.24 ms per token,  4208.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10295.05 ms /   223 tokens (   46.17 ms per token,    21.66 tokens per second)\n",
      "llama_print_timings:        eval time =   47857.14 ms /   157 runs   (  304.82 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =   58555.10 ms /   380 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      83.22 ms /   353 runs   (    0.24 ms per token,  4241.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10759.94 ms /   171 tokens (   62.92 ms per token,    15.89 tokens per second)\n",
      "llama_print_timings:        eval time =  104330.74 ms /   352 runs   (  296.39 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =  116033.99 ms /   523 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     137.11 ms /   561 runs   (    0.24 ms per token,  4091.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  166826.88 ms /   561 runs   (  297.37 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =  168397.28 ms /   562 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      41.79 ms /   172 runs   (    0.24 ms per token,  4115.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10521.56 ms /   225 tokens (   46.76 ms per token,    21.38 tokens per second)\n",
      "llama_print_timings:        eval time =   52947.56 ms /   171 runs   (  309.63 ms per token,     3.23 tokens per second)\n",
      "llama_print_timings:       total time =   63911.31 ms /   396 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     129.39 ms /   538 runs   (    0.24 ms per token,  4158.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10578.54 ms /   192 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =  160228.38 ms /   537 runs   (  298.38 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  172297.44 ms /   729 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      98.15 ms /   404 runs   (    0.24 ms per token,  4116.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  121551.03 ms /   404 runs   (  300.87 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  122642.96 ms /   405 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      50.06 ms /   203 runs   (    0.25 ms per token,  4055.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10650.68 ms /   273 tokens (   39.01 ms per token,    25.63 tokens per second)\n",
      "llama_print_timings:        eval time =   60428.28 ms /   202 runs   (  299.15 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =   71603.72 ms /   475 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     143.96 ms /   604 runs   (    0.24 ms per token,  4195.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10695.18 ms /   221 tokens (   48.39 ms per token,    20.66 tokens per second)\n",
      "llama_print_timings:        eval time =  180814.73 ms /   603 runs   (  299.86 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  193211.13 ms /   824 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     108.51 ms /   462 runs   (    0.23 ms per token,  4257.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10396.72 ms /   219 tokens (   47.47 ms per token,    21.06 tokens per second)\n",
      "llama_print_timings:        eval time =  139171.72 ms /   461 runs   (  301.89 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  150824.74 ms /   680 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      46.18 ms /   187 runs   (    0.25 ms per token,  4049.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10744.85 ms /   304 tokens (   35.34 ms per token,    28.29 tokens per second)\n",
      "llama_print_timings:        eval time =   54666.78 ms /   186 runs   (  293.91 ms per token,     3.40 tokens per second)\n",
      "llama_print_timings:       total time =   65897.95 ms /   490 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     135.42 ms /   571 runs   (    0.24 ms per token,  4216.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10407.74 ms /   205 tokens (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_print_timings:        eval time =  169249.04 ms /   570 runs   (  296.93 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =  181253.68 ms /   775 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     236.94 ms /  1000 runs   (    0.24 ms per token,  4220.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10610.38 ms /   200 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =  304293.66 ms /   999 runs   (  304.60 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  317944.35 ms /  1199 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      19.50 ms /    82 runs   (    0.24 ms per token,  4205.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10230.59 ms /   152 tokens (   67.31 ms per token,    14.86 tokens per second)\n",
      "llama_print_timings:        eval time =   24294.45 ms /    81 runs   (  299.93 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =   34733.54 ms /   233 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      20.19 ms /    85 runs   (    0.24 ms per token,  4210.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10282.02 ms /   102 tokens (  100.80 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:        eval time =   25845.26 ms /    84 runs   (  307.68 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =   36338.88 ms /   186 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      21.76 ms /    90 runs   (    0.24 ms per token,  4136.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10417.86 ms /    91 tokens (  114.48 ms per token,     8.73 tokens per second)\n",
      "llama_print_timings:        eval time =   27330.18 ms /    89 runs   (  307.08 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =   37976.36 ms /   180 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      16.88 ms /    70 runs   (    0.24 ms per token,  4145.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10354.69 ms /   165 tokens (   62.76 ms per token,    15.93 tokens per second)\n",
      "llama_print_timings:        eval time =   22461.85 ms /    69 runs   (  325.53 ms per token,     3.07 tokens per second)\n",
      "llama_print_timings:       total time =   32994.58 ms /   234 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      20.69 ms /    95 runs   (    0.22 ms per token,  4590.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10357.28 ms /    83 tokens (  124.79 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:        eval time =   28321.28 ms /    94 runs   (  301.29 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =   38918.03 ms /   177 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      21.99 ms /   100 runs   (    0.22 ms per token,  4548.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10172.27 ms /    83 tokens (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:        eval time =   29165.51 ms /    99 runs   (  294.60 ms per token,     3.39 tokens per second)\n",
      "llama_print_timings:       total time =   39588.68 ms /   182 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      16.36 ms /    66 runs   (    0.25 ms per token,  4033.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10420.09 ms /   127 tokens (   82.05 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:        eval time =   19687.32 ms /    65 runs   (  302.88 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =   30272.91 ms /   192 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      63.73 ms /   268 runs   (    0.24 ms per token,  4205.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10369.42 ms /    83 tokens (  124.93 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:        eval time =   81259.24 ms /   267 runs   (  304.34 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =   92333.66 ms /   350 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      52.53 ms /   220 runs   (    0.24 ms per token,  4187.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   67838.03 ms /   220 runs   (  308.35 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =   68407.64 ms /   221 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      28.41 ms /   120 runs   (    0.24 ms per token,  4223.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10126.85 ms /   123 tokens (   82.33 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:        eval time =   35738.55 ms /   119 runs   (  300.32 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =   46167.69 ms /   242 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     174.59 ms /   715 runs   (    0.24 ms per token,  4095.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10348.20 ms /   137 tokens (   75.53 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =  210973.97 ms /   714 runs   (  295.48 ms per token,     3.38 tokens per second)\n",
      "llama_print_timings:       total time =  223372.08 ms /   851 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     169.70 ms /   692 runs   (    0.25 ms per token,  4077.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  207407.60 ms /   692 runs   (  299.72 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =  209399.16 ms /   693 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    40 runs   (    0.23 ms per token,  4308.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10232.51 ms /   138 tokens (   74.15 ms per token,    13.49 tokens per second)\n",
      "llama_print_timings:        eval time =   11487.21 ms /    39 runs   (  294.54 ms per token,     3.40 tokens per second)\n",
      "llama_print_timings:       total time =   21819.37 ms /   177 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     162.90 ms /   676 runs   (    0.24 ms per token,  4149.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9991.49 ms /    58 tokens (  172.27 ms per token,     5.80 tokens per second)\n",
      "llama_print_timings:        eval time =  203037.46 ms /   675 runs   (  300.80 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  214952.29 ms /   733 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     164.44 ms /   690 runs   (    0.24 ms per token,  4196.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  208572.80 ms /   690 runs   (  302.28 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  210542.31 ms /   691 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    50 runs   (    0.24 ms per token,  4219.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10350.52 ms /   140 tokens (   73.93 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14917.18 ms /    49 runs   (  304.43 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =   25393.13 ms /   189 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     171.63 ms /   723 runs   (    0.24 ms per token,  4212.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9985.91 ms /    68 tokens (  146.85 ms per token,     6.81 tokens per second)\n",
      "llama_print_timings:        eval time =  217467.81 ms /   722 runs   (  301.20 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  229534.53 ms /   790 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      71.34 ms /   296 runs   (    0.24 ms per token,  4148.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10428.68 ms /    66 tokens (  158.01 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:        eval time =   87835.67 ms /   295 runs   (  297.75 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =   99047.45 ms /   361 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      14.60 ms /    61 runs   (    0.24 ms per token,  4179.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10118.53 ms /   137 tokens (   73.86 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:        eval time =   18494.49 ms /    60 runs   (  308.24 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =   28766.02 ms /   197 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     101.69 ms /   423 runs   (    0.24 ms per token,  4159.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10175.36 ms /    78 tokens (  130.45 ms per token,     7.67 tokens per second)\n",
      "llama_print_timings:        eval time =  130143.14 ms /   422 runs   (  308.40 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =  141469.07 ms /   500 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     122.67 ms /   519 runs   (    0.24 ms per token,  4230.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10354.85 ms /    75 tokens (  138.06 ms per token,     7.24 tokens per second)\n",
      "llama_print_timings:        eval time =  154366.83 ms /   518 runs   (  298.01 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =  166161.65 ms /   593 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      22.66 ms /    91 runs   (    0.25 ms per token,  4015.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10444.75 ms /   161 tokens (   64.87 ms per token,    15.41 tokens per second)\n",
      "llama_print_timings:        eval time =   28049.67 ms /    90 runs   (  311.66 ms per token,     3.21 tokens per second)\n",
      "llama_print_timings:       total time =   38727.42 ms /   251 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     131.83 ms /   562 runs   (    0.23 ms per token,  4263.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10506.21 ms /   108 tokens (   97.28 ms per token,    10.28 tokens per second)\n",
      "llama_print_timings:        eval time =  168870.88 ms /   561 runs   (  301.02 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  180947.00 ms /   669 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      82.64 ms /   364 runs   (    0.23 ms per token,  4404.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10139.62 ms /   105 tokens (   96.57 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:        eval time =  108752.22 ms /   363 runs   (  299.59 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =  119866.45 ms /   468 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      82.55 ms /   347 runs   (    0.24 ms per token,  4203.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10613.33 ms /   191 tokens (   55.57 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =  104636.51 ms /   346 runs   (  302.42 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  116179.23 ms /   537 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      93.04 ms /   400 runs   (    0.23 ms per token,  4299.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11098.16 ms /   370 tokens (   30.00 ms per token,    33.34 tokens per second)\n",
      "llama_print_timings:        eval time =  122220.23 ms /   399 runs   (  306.32 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =  134391.27 ms /   769 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     104.42 ms /   436 runs   (    0.24 ms per token,  4175.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11396.01 ms /   371 tokens (   30.72 ms per token,    32.56 tokens per second)\n",
      "llama_print_timings:        eval time =  133295.05 ms /   435 runs   (  306.43 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =  145884.80 ms /   806 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      22.57 ms /    90 runs   (    0.25 ms per token,  3987.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10524.50 ms /   164 tokens (   64.17 ms per token,    15.58 tokens per second)\n",
      "llama_print_timings:        eval time =   26950.02 ms /    89 runs   (  302.81 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =   37703.80 ms /   253 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     200.32 ms /   818 runs   (    0.24 ms per token,  4083.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10203.87 ms /   107 tokens (   95.36 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:        eval time =  241814.17 ms /   817 runs   (  295.98 ms per token,     3.38 tokens per second)\n",
      "llama_print_timings:       total time =  254424.72 ms /   924 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     117.49 ms /   474 runs   (    0.25 ms per token,  4034.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10067.90 ms /    99 tokens (  101.70 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:        eval time =  143022.44 ms /   473 runs   (  302.37 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  154388.71 ms /   572 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     108.58 ms /   454 runs   (    0.24 ms per token,  4181.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10675.66 ms /   166 tokens (   64.31 ms per token,    15.55 tokens per second)\n",
      "llama_print_timings:        eval time =  137926.61 ms /   453 runs   (  304.47 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  149847.55 ms /   619 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     100.10 ms /   426 runs   (    0.23 ms per token,  4255.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11800.50 ms /   471 tokens (   25.05 ms per token,    39.91 tokens per second)\n",
      "llama_print_timings:        eval time =  131020.20 ms /   425 runs   (  308.28 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =  143977.81 ms /   896 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     108.90 ms /   463 runs   (    0.24 ms per token,  4251.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11018.74 ms /   468 tokens (   23.54 ms per token,    42.47 tokens per second)\n",
      "llama_print_timings:        eval time =  142039.66 ms /   462 runs   (  307.45 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =  154324.03 ms /   930 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      81.51 ms /   340 runs   (    0.24 ms per token,  4171.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21453.00 ms /   554 tokens (   38.72 ms per token,    25.82 tokens per second)\n",
      "llama_print_timings:        eval time =  103869.15 ms /   339 runs   (  306.40 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =  126232.11 ms /   893 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      76.99 ms /   310 runs   (    0.25 ms per token,  4026.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11159.88 ms /   360 tokens (   31.00 ms per token,    32.26 tokens per second)\n",
      "llama_print_timings:        eval time =   93759.69 ms /   309 runs   (  303.43 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  105753.08 ms /   669 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     100.51 ms /   432 runs   (    0.23 ms per token,  4298.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  130085.04 ms /   432 runs   (  301.12 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  131252.77 ms /   433 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      15.55 ms /    68 runs   (    0.23 ms per token,  4372.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10771.50 ms /   280 tokens (   38.47 ms per token,    25.99 tokens per second)\n",
      "llama_print_timings:        eval time =   20146.67 ms /    67 runs   (  300.70 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =   31090.58 ms /   347 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      17.23 ms /    82 runs   (    0.21 ms per token,  4758.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10497.92 ms /    85 tokens (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:        eval time =   23798.02 ms /    81 runs   (  293.80 ms per token,     3.40 tokens per second)\n",
      "llama_print_timings:       total time =   34495.71 ms /   166 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      18.76 ms /    89 runs   (    0.21 ms per token,  4743.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   27296.38 ms /    89 runs   (  306.70 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =   27514.54 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =       9.55 ms /    41 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10324.53 ms /   122 tokens (   84.63 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11909.18 ms /    40 runs   (  297.73 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =   22333.33 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      84.15 ms /   340 runs   (    0.25 ms per token,  4040.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10067.38 ms /    58 tokens (  173.58 ms per token,     5.76 tokens per second)\n",
      "llama_print_timings:        eval time =  101012.04 ms /   339 runs   (  297.97 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =  111987.98 ms /   397 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      65.83 ms /   274 runs   (    0.24 ms per token,  4162.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10000.50 ms /    50 tokens (  200.01 ms per token,     5.00 tokens per second)\n",
      "llama_print_timings:        eval time =   83896.91 ms /   273 runs   (  307.31 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =   94611.25 ms /   323 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     139.71 ms /   573 runs   (    0.24 ms per token,  4101.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10517.73 ms /   141 tokens (   74.59 ms per token,    13.41 tokens per second)\n",
      "llama_print_timings:        eval time =  169306.10 ms /   572 runs   (  295.99 ms per token,     3.38 tokens per second)\n",
      "llama_print_timings:       total time =  181427.45 ms /   713 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     141.81 ms /   575 runs   (    0.25 ms per token,  4054.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21912.50 ms /   591 tokens (   37.08 ms per token,    26.97 tokens per second)\n",
      "llama_print_timings:        eval time =  178643.27 ms /   574 runs   (  311.23 ms per token,     3.21 tokens per second)\n",
      "llama_print_timings:       total time =  202178.62 ms /  1165 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      49.92 ms /   208 runs   (    0.24 ms per token,  4166.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22245.82 ms /   589 tokens (   37.77 ms per token,    26.48 tokens per second)\n",
      "llama_print_timings:        eval time =   64273.17 ms /   207 runs   (  310.50 ms per token,     3.22 tokens per second)\n",
      "llama_print_timings:       total time =   87060.02 ms /   796 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     132.58 ms /   541 runs   (    0.25 ms per token,  4080.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22121.43 ms /   673 tokens (   32.87 ms per token,    30.42 tokens per second)\n",
      "llama_print_timings:        eval time =  170959.56 ms /   540 runs   (  316.59 ms per token,     3.16 tokens per second)\n",
      "llama_print_timings:       total time =  194594.68 ms /  1213 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      90.86 ms /   372 runs   (    0.24 ms per token,  4094.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21743.65 ms /   554 tokens (   39.25 ms per token,    25.48 tokens per second)\n",
      "llama_print_timings:        eval time =  114402.18 ms /   371 runs   (  308.36 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =  137154.73 ms /   925 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     177.15 ms /   729 runs   (    0.24 ms per token,  4115.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  217412.40 ms /   729 runs   (  298.23 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  219522.28 ms /   730 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     190.91 ms /   772 runs   (    0.25 ms per token,  4043.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21615.07 ms /   641 tokens (   33.72 ms per token,    29.66 tokens per second)\n",
      "llama_print_timings:        eval time =  239200.33 ms /   771 runs   (  310.25 ms per token,     3.22 tokens per second)\n",
      "llama_print_timings:       total time =  263082.17 ms /  1412 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     208.03 ms /   848 runs   (    0.25 ms per token,  4076.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22400.61 ms /   790 tokens (   28.36 ms per token,    35.27 tokens per second)\n",
      "llama_print_timings:        eval time =  258886.24 ms /   847 runs   (  305.65 ms per token,     3.27 tokens per second)\n",
      "llama_print_timings:       total time =  283804.10 ms /  1637 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     171.66 ms /   702 runs   (    0.24 ms per token,  4089.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22048.58 ms /   785 tokens (   28.09 ms per token,    35.60 tokens per second)\n",
      "llama_print_timings:        eval time =  212159.75 ms /   701 runs   (  302.65 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  236220.07 ms /  1486 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     144.32 ms /   585 runs   (    0.25 ms per token,  4053.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22401.09 ms /   872 tokens (   25.69 ms per token,    38.93 tokens per second)\n",
      "llama_print_timings:        eval time =  178191.27 ms /   584 runs   (  305.12 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  202256.41 ms /  1456 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      70.66 ms /   289 runs   (    0.24 ms per token,  4089.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21681.10 ms /   603 tokens (   35.96 ms per token,    27.81 tokens per second)\n",
      "llama_print_timings:        eval time =   85823.79 ms /   288 runs   (  298.00 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =  108272.29 ms /   891 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     147.72 ms /   606 runs   (    0.24 ms per token,  4102.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21596.33 ms /   598 tokens (   36.11 ms per token,    27.69 tokens per second)\n",
      "llama_print_timings:        eval time =  181869.32 ms /   605 runs   (  300.61 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  205185.46 ms /  1203 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     142.27 ms /   579 runs   (    0.25 ms per token,  4069.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21746.82 ms /   685 tokens (   31.75 ms per token,    31.50 tokens per second)\n",
      "llama_print_timings:        eval time =  172411.61 ms /   578 runs   (  298.29 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  195794.13 ms /  1263 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      92.34 ms /   377 runs   (    0.24 ms per token,  4082.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21877.43 ms /   597 tokens (   36.65 ms per token,    27.29 tokens per second)\n",
      "llama_print_timings:        eval time =  110526.48 ms /   376 runs   (  293.95 ms per token,     3.40 tokens per second)\n",
      "llama_print_timings:       total time =  133427.59 ms /   973 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     123.98 ms /   507 runs   (    0.24 ms per token,  4089.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  151268.68 ms /   507 runs   (  298.36 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  152684.35 ms /   508 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     142.03 ms /   574 runs   (    0.25 ms per token,  4041.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22682.21 ms /   679 tokens (   33.41 ms per token,    29.94 tokens per second)\n",
      "llama_print_timings:        eval time =  173938.78 ms /   573 runs   (  303.56 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =  198257.50 ms /  1252 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     120.72 ms /   501 runs   (    0.24 ms per token,  4150.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21632.85 ms /   587 tokens (   36.85 ms per token,    27.13 tokens per second)\n",
      "llama_print_timings:        eval time =  153791.98 ms /   500 runs   (  307.58 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =  176816.06 ms /  1087 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     148.61 ms /   608 runs   (    0.24 ms per token,  4091.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21772.61 ms /   588 tokens (   37.03 ms per token,    27.01 tokens per second)\n",
      "llama_print_timings:        eval time =  185226.84 ms /   607 runs   (  305.15 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  208720.81 ms /  1195 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     177.28 ms /   721 runs   (    0.25 ms per token,  4067.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21515.86 ms /   558 tokens (   38.56 ms per token,    25.93 tokens per second)\n",
      "llama_print_timings:        eval time =  217349.80 ms /   720 runs   (  301.87 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  240958.95 ms /  1278 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     182.41 ms /   743 runs   (    0.25 ms per token,  4073.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21992.82 ms /   739 tokens (   29.76 ms per token,    33.60 tokens per second)\n",
      "llama_print_timings:        eval time =  224329.02 ms /   742 runs   (  302.33 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  248491.13 ms /  1481 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      68.28 ms /   280 runs   (    0.24 ms per token,  4100.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22278.17 ms /   737 tokens (   30.23 ms per token,    33.08 tokens per second)\n",
      "llama_print_timings:        eval time =   85467.88 ms /   279 runs   (  306.34 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =  108492.57 ms /  1016 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     144.20 ms /   590 runs   (    0.24 ms per token,  4091.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21730.09 ms /   674 tokens (   32.24 ms per token,    31.02 tokens per second)\n",
      "llama_print_timings:        eval time =  179112.27 ms /   589 runs   (  304.10 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =  202522.30 ms /  1263 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     142.31 ms /   583 runs   (    0.24 ms per token,  4096.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21484.73 ms /   603 tokens (   35.63 ms per token,    28.07 tokens per second)\n",
      "llama_print_timings:        eval time =  177387.60 ms /   582 runs   (  304.79 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  200512.93 ms /  1185 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     143.98 ms /   587 runs   (    0.25 ms per token,  4077.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21880.16 ms /   604 tokens (   36.23 ms per token,    27.60 tokens per second)\n",
      "llama_print_timings:        eval time =  174735.64 ms /   586 runs   (  298.18 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  198279.35 ms /  1190 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      95.90 ms /   392 runs   (    0.24 ms per token,  4087.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22648.86 ms /   576 tokens (   39.32 ms per token,    25.43 tokens per second)\n",
      "llama_print_timings:        eval time =  117915.59 ms /   391 runs   (  301.57 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  141639.02 ms /   967 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     160.37 ms /   659 runs   (    0.24 ms per token,  4109.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11263.90 ms /   410 tokens (   27.47 ms per token,    36.40 tokens per second)\n",
      "llama_print_timings:        eval time =  197960.68 ms /   658 runs   (  300.85 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  211113.17 ms /  1068 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      92.51 ms /   377 runs   (    0.25 ms per token,  4075.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11227.88 ms /   405 tokens (   27.72 ms per token,    36.07 tokens per second)\n",
      "llama_print_timings:        eval time =  112387.93 ms /   376 runs   (  298.90 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  124634.18 ms /   781 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      11.11 ms /    45 runs   (    0.25 ms per token,  4051.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10525.91 ms /   119 tokens (   88.45 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:        eval time =   13496.23 ms /    44 runs   (  306.73 ms per token,     3.26 tokens per second)\n",
      "llama_print_timings:       total time =   24136.81 ms /   163 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      23.09 ms /    97 runs   (    0.24 ms per token,  4200.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10174.25 ms /    65 tokens (  156.53 ms per token,     6.39 tokens per second)\n",
      "llama_print_timings:        eval time =   30738.35 ms /    96 runs   (  320.19 ms per token,     3.12 tokens per second)\n",
      "llama_print_timings:       total time =   41158.58 ms /   161 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      81.69 ms /   338 runs   (    0.24 ms per token,  4137.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10404.44 ms /    59 tokens (  176.35 ms per token,     5.67 tokens per second)\n",
      "llama_print_timings:        eval time =  101655.41 ms /   337 runs   (  301.65 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  112965.10 ms /   396 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    29 runs   (    0.24 ms per token,  4159.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10343.97 ms /   120 tokens (   86.20 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:        eval time =    8266.30 ms /    28 runs   (  295.22 ms per token,     3.39 tokens per second)\n",
      "llama_print_timings:       total time =   18682.79 ms /   148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      76.99 ms /   315 runs   (    0.24 ms per token,  4091.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10012.45 ms /    46 tokens (  217.66 ms per token,     4.59 tokens per second)\n",
      "llama_print_timings:        eval time =   94231.97 ms /   314 runs   (  300.10 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =  105082.08 ms /   360 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      89.28 ms /   373 runs   (    0.24 ms per token,  4177.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9772.33 ms /    43 tokens (  227.26 ms per token,     4.40 tokens per second)\n",
      "llama_print_timings:        eval time =  112909.10 ms /   372 runs   (  303.52 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =  123679.05 ms /   415 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      11.64 ms /    49 runs   (    0.24 ms per token,  4211.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10065.84 ms /   129 tokens (   78.03 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13896.19 ms /    48 runs   (  289.50 ms per token,     3.45 tokens per second)\n",
      "llama_print_timings:       total time =   24084.68 ms /   177 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      80.78 ms /   332 runs   (    0.24 ms per token,  4109.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10118.71 ms /    66 tokens (  153.31 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:        eval time =   99887.26 ms /   331 runs   (  301.77 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  110895.45 ms /   397 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      46.90 ms /   190 runs   (    0.25 ms per token,  4050.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10037.29 ms /    65 tokens (  154.42 ms per token,     6.48 tokens per second)\n",
      "llama_print_timings:        eval time =   56859.93 ms /   189 runs   (  300.85 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =   67386.06 ms /   254 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      21.09 ms /    83 runs   (    0.25 ms per token,  3934.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10290.42 ms /   149 tokens (   69.06 ms per token,    14.48 tokens per second)\n",
      "llama_print_timings:        eval time =   25725.36 ms /    82 runs   (  313.72 ms per token,     3.19 tokens per second)\n",
      "llama_print_timings:       total time =   36224.27 ms /   231 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      73.21 ms /   299 runs   (    0.24 ms per token,  4084.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10354.31 ms /    96 tokens (  107.86 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:        eval time =   90426.06 ms /   298 runs   (  303.44 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  101575.12 ms /   394 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      59.15 ms /   238 runs   (    0.25 ms per token,  4023.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10535.76 ms /    96 tokens (  109.75 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:        eval time =   70335.76 ms /   237 runs   (  296.78 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =   81495.55 ms /   333 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      20.32 ms /    87 runs   (    0.23 ms per token,  4280.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10576.53 ms /   183 tokens (   57.80 ms per token,    17.30 tokens per second)\n",
      "llama_print_timings:        eval time =   24730.63 ms /    86 runs   (  287.57 ms per token,     3.48 tokens per second)\n",
      "llama_print_timings:       total time =   35526.47 ms /   269 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      59.84 ms /   247 runs   (    0.24 ms per token,  4127.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9995.18 ms /   100 tokens (   99.95 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:        eval time =   72961.18 ms /   246 runs   (  296.59 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =   83600.87 ms /   346 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     150.91 ms /   632 runs   (    0.24 ms per token,  4187.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  188795.46 ms /   632 runs   (  298.73 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  190583.87 ms /   633 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      30.30 ms /   133 runs   (    0.23 ms per token,  4388.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10435.60 ms /   171 tokens (   61.03 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:        eval time =   39126.03 ms /   132 runs   (  296.41 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =   49899.57 ms /   303 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      80.70 ms /   323 runs   (    0.25 ms per token,  4002.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10356.88 ms /   150 tokens (   69.05 ms per token,    14.48 tokens per second)\n",
      "llama_print_timings:        eval time =   95692.57 ms /   322 runs   (  297.18 ms per token,     3.36 tokens per second)\n",
      "llama_print_timings:       total time =  106909.74 ms /   472 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     126.21 ms /   508 runs   (    0.25 ms per token,  4025.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  153345.60 ms /   508 runs   (  301.86 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  154760.49 ms /   509 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      29.17 ms /   120 runs   (    0.24 ms per token,  4114.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10743.62 ms /   210 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:        eval time =   37603.66 ms /   119 runs   (  316.00 ms per token,     3.16 tokens per second)\n",
      "llama_print_timings:       total time =   48652.29 ms /   329 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     131.85 ms /   544 runs   (    0.24 ms per token,  4125.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10351.40 ms /   133 tokens (   77.83 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:        eval time =  162018.05 ms /   543 runs   (  298.38 ms per token,     3.35 tokens per second)\n",
      "llama_print_timings:       total time =  173884.19 ms /   676 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     184.23 ms /   756 runs   (    0.24 ms per token,  4103.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10371.96 ms /   134 tokens (   77.40 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:        eval time =  223371.84 ms /   755 runs   (  295.86 ms per token,     3.38 tokens per second)\n",
      "llama_print_timings:       total time =  235926.80 ms /   889 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      83.37 ms /   346 runs   (    0.24 ms per token,  4150.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10385.62 ms /   124 tokens (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:        eval time =  105317.54 ms /   345 runs   (  305.27 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  116626.42 ms /   469 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     135.57 ms /   560 runs   (    0.24 ms per token,  4130.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10999.61 ms /   363 tokens (   30.30 ms per token,    33.00 tokens per second)\n",
      "llama_print_timings:        eval time =  170066.40 ms /   559 runs   (  304.23 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =  182625.76 ms /   922 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      93.50 ms /   382 runs   (    0.24 ms per token,  4085.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11290.85 ms /   355 tokens (   31.81 ms per token,    31.44 tokens per second)\n",
      "llama_print_timings:        eval time =  115547.46 ms /   381 runs   (  303.27 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  127867.85 ms /   736 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      83.68 ms /   341 runs   (    0.25 ms per token,  4074.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11219.09 ms /   446 tokens (   25.15 ms per token,    39.75 tokens per second)\n",
      "llama_print_timings:        eval time =  100878.71 ms /   340 runs   (  296.70 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =  113009.38 ms /   786 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     183.59 ms /   755 runs   (    0.24 ms per token,  4112.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11030.04 ms /   359 tokens (   30.72 ms per token,    32.55 tokens per second)\n",
      "llama_print_timings:        eval time =  227764.24 ms /   754 runs   (  302.07 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  240972.28 ms /  1113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     143.13 ms /   584 runs   (    0.25 ms per token,  4080.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10962.06 ms /   357 tokens (   30.71 ms per token,    32.57 tokens per second)\n",
      "llama_print_timings:        eval time =  177783.71 ms /   583 runs   (  304.95 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  190384.24 ms /   940 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     112.25 ms /   460 runs   (    0.24 ms per token,  4098.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11198.28 ms /   441 tokens (   25.39 ms per token,    39.38 tokens per second)\n",
      "llama_print_timings:        eval time =  138412.40 ms /   459 runs   (  301.55 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =  150871.00 ms /   900 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     152.39 ms /   622 runs   (    0.25 ms per token,  4081.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11215.70 ms /   480 tokens (   23.37 ms per token,    42.80 tokens per second)\n",
      "llama_print_timings:        eval time =  190119.40 ms /   621 runs   (  306.15 ms per token,     3.27 tokens per second)\n",
      "llama_print_timings:       total time =  203106.48 ms /  1101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     168.47 ms /   707 runs   (    0.24 ms per token,  4196.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11372.84 ms /   473 tokens (   24.04 ms per token,    41.59 tokens per second)\n",
      "llama_print_timings:        eval time =  213741.19 ms /   706 runs   (  302.75 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  227131.12 ms /  1179 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      19.75 ms /    83 runs   (    0.24 ms per token,  4203.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10147.20 ms /   124 tokens (   81.83 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:        eval time =   24902.10 ms /    82 runs   (  303.68 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =   35256.05 ms /   206 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     152.19 ms /   630 runs   (    0.24 ms per token,  4139.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10400.68 ms /   101 tokens (  102.98 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:        eval time =  192359.97 ms /   629 runs   (  305.82 ms per token,     3.27 tokens per second)\n",
      "llama_print_timings:       total time =  204528.49 ms /   730 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     194.95 ms /   817 runs   (    0.24 ms per token,  4190.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10356.76 ms /    96 tokens (  107.88 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:        eval time =  246218.10 ms /   816 runs   (  301.74 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  258953.55 ms /   912 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     147.28 ms /   596 runs   (    0.25 ms per token,  4046.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10539.45 ms /   172 tokens (   61.28 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:        eval time =  180714.60 ms /   595 runs   (  303.72 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =  192937.31 ms /   767 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     148.63 ms /   611 runs   (    0.24 ms per token,  4110.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21447.84 ms /   615 tokens (   34.87 ms per token,    28.67 tokens per second)\n",
      "llama_print_timings:        eval time =  179889.63 ms /   610 runs   (  294.90 ms per token,     3.39 tokens per second)\n",
      "llama_print_timings:       total time =  203063.03 ms /  1225 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      34.53 ms /   142 runs   (    0.24 ms per token,  4112.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21405.16 ms /   614 tokens (   34.86 ms per token,    28.68 tokens per second)\n",
      "llama_print_timings:        eval time =   44052.40 ms /   141 runs   (  312.43 ms per token,     3.20 tokens per second)\n",
      "llama_print_timings:       total time =   65828.16 ms /   755 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     138.72 ms /   562 runs   (    0.25 ms per token,  4051.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23208.01 ms /   698 tokens (   33.25 ms per token,    30.08 tokens per second)\n",
      "llama_print_timings:        eval time =  173436.52 ms /   561 runs   (  309.16 ms per token,     3.23 tokens per second)\n",
      "llama_print_timings:       total time =  198239.36 ms /  1259 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     139.02 ms /   561 runs   (    0.25 ms per token,  4035.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21809.21 ms /   580 tokens (   37.60 ms per token,    26.59 tokens per second)\n",
      "llama_print_timings:        eval time =  167554.46 ms /   560 runs   (  299.20 ms per token,     3.34 tokens per second)\n",
      "llama_print_timings:       total time =  190944.35 ms /  1140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      91.81 ms /   373 runs   (    0.25 ms per token,  4062.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  115346.02 ms /   373 runs   (  309.24 ms per token,     3.23 tokens per second)\n",
      "llama_print_timings:       total time =  116361.89 ms /   374 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     127.89 ms /   538 runs   (    0.24 ms per token,  4206.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22707.11 ms /   983 tokens (   23.10 ms per token,    43.29 tokens per second)\n",
      "llama_print_timings:        eval time =  162705.16 ms /   537 runs   (  302.99 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  186918.93 ms /  1520 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     103.08 ms /   435 runs   (    0.24 ms per token,  4220.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22173.76 ms /   556 tokens (   39.88 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:        eval time =  131532.66 ms /   434 runs   (  303.07 ms per token,     3.30 tokens per second)\n",
      "llama_print_timings:       total time =  154900.93 ms /   990 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      89.72 ms /   374 runs   (    0.24 ms per token,  4168.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21277.64 ms /   551 tokens (   38.62 ms per token,    25.90 tokens per second)\n",
      "llama_print_timings:        eval time =  117564.63 ms /   373 runs   (  315.19 ms per token,     3.17 tokens per second)\n",
      "llama_print_timings:       total time =  139846.77 ms /   924 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     101.34 ms /   414 runs   (    0.24 ms per token,  4085.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =   47955.30 ms /   541 tokens (   88.64 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:        eval time =  127435.65 ms /   413 runs   (  308.56 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =  176514.48 ms /   954 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      49.52 ms /   206 runs   (    0.24 ms per token,  4159.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11447.82 ms /   434 tokens (   26.38 ms per token,    37.91 tokens per second)\n",
      "llama_print_timings:        eval time =   61933.86 ms /   205 runs   (  302.12 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =   73916.10 ms /   639 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     197.75 ms /   818 runs   (    0.24 ms per token,  4136.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11339.98 ms /   427 tokens (   26.56 ms per token,    37.65 tokens per second)\n",
      "llama_print_timings:        eval time =  251003.01 ms /   817 runs   (  307.23 ms per token,     3.25 tokens per second)\n",
      "llama_print_timings:       total time =  264758.11 ms /  1244 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     109.99 ms /   450 runs   (    0.24 ms per token,  4091.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   48440.04 ms /   514 tokens (   94.24 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:        eval time =  135493.30 ms /   449 runs   (  301.77 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =  185172.20 ms /   963 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =     138.31 ms /   571 runs   (    0.24 ms per token,  4128.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11030.69 ms /   467 tokens (   23.62 ms per token,    42.34 tokens per second)\n",
      "llama_print_timings:        eval time =  173958.79 ms /   570 runs   (  305.19 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =  186583.94 ms /  1037 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      27.54 ms /   121 runs   (    0.23 ms per token,  4393.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11028.17 ms /   466 tokens (   23.67 ms per token,    42.26 tokens per second)\n",
      "llama_print_timings:        eval time =   36090.05 ms /   120 runs   (  300.75 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =   47423.10 ms /   586 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      88.53 ms /   362 runs   (    0.24 ms per token,  4089.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21531.22 ms /   550 tokens (   39.15 ms per token,    25.54 tokens per second)\n",
      "llama_print_timings:        eval time =  106441.51 ms /   361 runs   (  294.85 ms per token,     3.39 tokens per second)\n",
      "llama_print_timings:       total time =  128947.29 ms /   911 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10998.73 ms\n",
      "llama_print_timings:      sample time =      90.46 ms /   371 runs   (    0.24 ms per token,  4101.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11454.41 ms /   375 tokens (   30.55 ms per token,    32.74 tokens per second)\n",
      "llama_print_timings:        eval time =  109088.29 ms /   370 runs   (  294.83 ms per token,     3.39 tokens per second)\n",
      "llama_print_timings:       total time =  121538.59 ms /   745 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "question=random.choice(questions)\n",
    "question_template = f\"\"\"以下の問題・質問・指示の類題を日本語で作成してください。\n",
    "・類題はもとの問題からは必ず情報を追加・修正・削除し、内容、形式、記述方式が全く異なるようにすること\n",
    "・作成した内容のみを出力すること\n",
    "\"\"\"\n",
    "while True:\n",
    "    q=question_template+question\n",
    "    try:\n",
    "        new_question=bot.ask(q).replace(\"#類題\",\"\").replace(\"#問題\",\"\").strip()[:3000]\n",
    "        record={\"question\":new_question}\n",
    "\n",
    "        a_gen(record)\n",
    "        with open(out_path, 'a') as f:\n",
    "            f.write(json.dumps(record,ensure_ascii=False)+\"\\n\")\n",
    "    except:\n",
    "        pass\n",
    "    question=new_question\n",
    "    #question=question[:random.randint(0,len(question))]\n",
    "    if random.randint(0,3)==0:\n",
    "        question=question[:int(len(question)*0.8)]\n",
    "    elif random.randint(0,3)==1:\n",
    "        question=question[int(len(question)*0.2):]\n",
    "    if random.randint(0,3)==0:\n",
    "        question=random.choice(questions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
