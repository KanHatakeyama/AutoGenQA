{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "jsonl_dirs=glob.glob('data_random_algorithm/*.jsonl')\n",
    "len(jsonl_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records=[]\n",
    "for jsonl_dir in jsonl_dirs:\n",
    "    with open(jsonl_dir) as f:\n",
    "        for line in f:\n",
    "            records.append(json.loads(line))\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_records=[]\n",
    "record=records[0]\n",
    "\n",
    "txt=record['autogen_text']\n",
    "def parse_qa(txt):\n",
    "    q_template=\"#問題:\"\n",
    "    a_template=\"#回答:\"\n",
    "\n",
    "    a_pos=txt.find(a_template)\n",
    "    q_pos=txt.find(q_template)\n",
    "\n",
    "    if a_pos==-1 or q_pos==-1:\n",
    "        return None,None\n",
    "    if txt.find(\"#問題1\")>0:\n",
    "        return None,None\n",
    "    a=txt[a_pos+len(a_template):].strip()\n",
    "    q=txt[q_pos+len(q_template):a_pos].strip()\n",
    "    if a==\"\" or q==\"\":\n",
    "        return None,None\n",
    "    return q,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_records=[]\n",
    "for record in records:\n",
    "    txt=record['autogen_text']\n",
    "    q,a=parse_qa(txt)\n",
    "    if q is not None and a is not None:\n",
    "        cleaned_records.append({'question':q,'answer':a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(cleaned_records)\n",
    "parquet_path='data_random_algorithm/1.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from huggingface_hub import HfApi, logging\n",
    "hf = HfApi()\n",
    "hf.upload_file(path_or_fileobj=parquet_path,\n",
    "                path_in_repo=f\"1.parquet\",\n",
    "                repo_id=\"kanhatakeyama/LogicalDatasetsByMixtral8x22b\", repo_type=\"dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
