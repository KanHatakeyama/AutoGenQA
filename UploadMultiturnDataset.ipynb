{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#マルチターンデータセットを統合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import re\n",
    "jsonl_path_list=glob.glob(\"data_multi_*/*.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "records=[]\n",
    "for jsonl_path in jsonl_path_list:\n",
    "    with open(jsonl_path,\"r\") as f:\n",
    "        for line in f:\n",
    "            records.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#きれいにする\n",
    "remove_words=[\n",
    "\"User:\",\n",
    "\"Assistant:\",\n",
    "\"ユーザー：\",\n",
    "\"アシスタント：\",\n",
    "\"ユーザー:\",\n",
    "\"アシスタント:\",\n",
    "]\n",
    "def clean_chat(txt):\n",
    "    for word in remove_words:\n",
    "        if txt.startswith(word):\n",
    "            txt=txt[len(word):]\n",
    "    txt=txt.strip()\n",
    "    if txt[0]==\"「\" and txt[-1]==\"」\":\n",
    "        txt=txt[1:-1]\n",
    "\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=\"「アートの世界において、巨匠と呼ばれる人物は誰がありますか？」\"\n",
    "clean_chat(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_full_auto_dialogue(txt):\n",
    "    if \"### 指示1:\" in txt and \"### 応答1:\" and \"### 指示2:\" in txt and \"### 応答2:\":\n",
    "        # 正規表現で「指示」と「応答」を抽出\n",
    "        pattern = r\"### 指示(\\d+):(.*?)\\n### 応答\\1:(.*?)(?=\\n### 指示|$)\"\n",
    "        matches = re.findall(pattern, txt, re.DOTALL)\n",
    "\n",
    "        # 辞書に変換\n",
    "        dialogue_dict = {}\n",
    "        add_flag=True\n",
    "        for match in matches:\n",
    "            idx = int(match[0])\n",
    "            if idx>=3:\n",
    "                continue\n",
    "            user_text = match[1].strip()\n",
    "            assistant_text = match[2].strip()\n",
    "            if len(user_text)<3:\n",
    "                add_flag=False\n",
    "                break\n",
    "            if assistant_text==\"\":\n",
    "                add_flag=False\n",
    "                break\n",
    "\n",
    "            if user_text.find(\"以下の情報を元に、UserとAssistantのやりとりを\")>=0:\n",
    "                add_flag=False\n",
    "                break\n",
    "\n",
    "            dialogue_dict[f\"q{idx}\"] = clean_chat(user_text)\n",
    "            dialogue_dict[f\"a{idx}\"] = clean_chat(assistant_text)\n",
    "\n",
    "        #最後にチェック\n",
    "        if \"q1\" in dialogue_dict and \"q2\" in dialogue_dict and \"a1\" in dialogue_dict and \"a2\" in dialogue_dict:\n",
    "            return dialogue_dict,add_flag\n",
    "    \n",
    "    return {},False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record=records[1]\n",
    "dialogues=[]\n",
    "\n",
    "invalid_records=[]\n",
    "for record in records:\n",
    "\n",
    "    #自動生成のdialogue\n",
    "    if \"autogen_text\" in record:\n",
    "        txt=record[\"autogen_text\"].strip()\n",
    "\n",
    "    #質問を与える場合\n",
    "    elif \"question\" in record and \"response\" in record:\n",
    "        txt=record[\"response\"].strip()\n",
    "    else:\n",
    "        invalid_records.append(record)\n",
    "        #print(\"invalid record:\",record)\n",
    "        #raise ValueError(record)\n",
    "\n",
    "    dialogue_dict,add_flag=parse_full_auto_dialogue(txt)\n",
    "    dialogue_dict[\"database\"]=record[\"database\"]\n",
    "    if add_flag:\n",
    "        dialogues.append(dialogue_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "from huggingface_hub import HfApi, logging\n",
    "df=pd.DataFrame(dialogues)\n",
    "df=df.reindex()\n",
    "parquet_path=\"data_multi_from_tsubame/1.parquet\"\n",
    "df.to_parquet(parquet_path)\n",
    "\n",
    "jsonl_path=\"data/multi.jsonl\"\n",
    "with open(jsonl_path,\"w\") as f:\n",
    "    for dialogue in dialogues:\n",
    "        f.write(json.dumps(dialogue,ensure_ascii=False)+\"\\n\")\n",
    "\n",
    "hf = HfApi()\n",
    "logging.set_verbosity_debug()\n",
    "hf.upload_file(#path_or_fileobj=parquet_path,\n",
    "                path_or_fileobj=jsonl_path,\n",
    "                #path_in_repo=f\"1.parquet\",\n",
    "                path_in_repo=f\"1.jsonl\",\n",
    "                repo_id=\"kanhatakeyama/AutoMultiTurnByMixtral8x22b\", repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
